<html>
<head>
  <title>Evernote Export</title>
  <basefont face="Tahoma" size="2" />
  <meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
  <meta name="exporter-version" content="Evernote Windows/274507; Windows/6.1.7601 Service Pack 1;"/>
  <style>
    body, td {
      font-family: Tahoma;
      font-size: 10pt;
    }
  </style>
</head>
<body>
<a name="2410"/>

<div>
<div style="word-wrap: break-word; -webkit-nbsp-mode: space; -webkit-line-break: after-white-space;">
1. 概率：
<div><br/></div><div>     1.1 定义   概率(P)robability: 对一件事情发生的可能性的衡量</div><div>     1.2 范围   0 &lt;= P &lt;= 1</div><div>     1.3 计算方法： </div><div>          1.3.1 根据个人置信</div><div>          1.3.2 根据历史数据</div><div>          1.3.3 根据模拟数据</div><div>     1.4 条件概率：</div><div>                         <img src="7.5 非线性回归 logistic regression_files/8694e4193ba45b55403595096b7d23c5.png" type="image/png" style="cursor: default;cursor: default;cursor: default;cursor: default;cursor: default;cursor: default;cursor: default;cursor: default;cursor: default;cursor: default;cursor: default;cursor: default;cursor: default;cursor: default;cursor: default;cursor: default;cursor: default;cursor: default;cursor: default;"/></div><div>2. Logistic Regression (逻辑回归)</div><div><br/></div><div>     2.1 例子</div><div>                    <img src="7.5 非线性回归 logistic regression_files/Image.png" type="image/png" style="cursor: default;cursor: default;cursor: default;cursor: default;cursor: default;cursor: default;cursor: default;cursor: default;cursor: default;cursor: default;cursor: default;cursor: default;cursor: default;cursor: default;cursor: default;cursor: default;cursor: default;cursor: default;"/></div><div>                                   h(x) &gt; 0.5</div><div><br/></div><div>               <img src="7.5 非线性回归 logistic regression_files/Image [1].png" type="image/png" height="275" style="cursor: default;cursor: default;cursor: default;cursor: default;cursor: default;cursor: default;cursor: default;cursor: default;cursor: default;cursor: default;cursor: default;cursor: default;cursor: default;cursor: default;cursor: default;cursor: default;cursor: default;cursor: default;" width="942"/></div><div><br/></div><div>                                             h(x) &gt; 0.2</div><div><br/></div><div>   2.2 基本模型</div><div>         测试数据为X（x0，x1，x2···xn）</div><div>         要学习的参数为： Θ（θ0，θ1，θ2，···θn）</div><div>          </div><div>     <img src="7.5 非线性回归 logistic regression_files/001QAImHgy6I1ohlalO18&690.jpg" type="image/jpeg" style="cursor: default;cursor: default;cursor: default;cursor: default;cursor: default;cursor: default;cursor: default;cursor: default;cursor: default;cursor: default;cursor: default;cursor: default;cursor: default;cursor: default;cursor: default;cursor: default;cursor: default;"/><br/></div><div>          向量表示：</div><div>          </div><div>     <img src="7.5 非线性回归 logistic regression_files/001QAImHgy6I1oi9u8Kae&690.jpg" type="image/jpeg" style="cursor: default;cursor: default;cursor: default;cursor: default;cursor: default;cursor: default;cursor: default;cursor: default;cursor: default;cursor: default;cursor: default;cursor: default;cursor: default;cursor: default;cursor: default;cursor: default;"/></div><div><br/></div><div>          </div><div>        处理二值数据，引入Sigmoid函数时曲线平滑化 </div><div>          </div><div>     <img src="7.5 非线性回归 logistic regression_files/001QAImHgy6I1ojfTjYaa&690.jpg" type="image/jpeg" style="cursor: default;cursor: default;cursor: default;cursor: default;cursor: default;cursor: default;cursor: default;cursor: default;cursor: default;cursor: default;cursor: default;cursor: default;cursor: default;cursor: default;cursor: default;"/><br/></div><div><br/></div><div>          <img src="7.5 非线性回归 logistic regression_files/001QAImHgy6I1ok9Brb61&690.jpg" type="image/jpeg" style="cursor: default;cursor: default;cursor: default;cursor: default;cursor: default;cursor: default;cursor: default;cursor: default;cursor: default;cursor: default;cursor: default;cursor: default;cursor: default;cursor: default;"/><br/><br/></div><div>          预测函数：</div><div>                    <img src="7.5 非线性回归 logistic regression_files/001QAImHgy6I1olbW3yfc&690.jpg" type="image/jpeg" style="cursor: default;cursor: default;cursor: default;cursor: default;cursor: default;cursor: default;cursor: default;cursor: default;cursor: default;cursor: default;cursor: default;cursor: default;cursor: default;"/></div><div><br/></div><div>          用概率表示：</div><div>          正例(y=1)：</div><div>                  </div><div>                         <img src="7.5 非线性回归 logistic regression_files/001QAImHgy6I1osqQ7lc7&690.jpg" type="image/jpeg" style="cursor: default;cursor: default;cursor: default;cursor: default;cursor: default;cursor: default;cursor: default;cursor: default;cursor: default;cursor: default;cursor: default;cursor: default;"/></div><div>          反例(y=0):</div><div>                              <img src="7.5 非线性回归 logistic regression_files/001QAImHgy6I1omK5aoc8&690.jpg" type="image/jpeg" style="cursor: default;cursor: default;cursor: default;cursor: default;cursor: default;cursor: default;cursor: default;cursor: default;cursor: default;cursor: default;cursor: default;"/></div><div><br/></div><div>       2.3  Cost函数</div><div>              线性回归:</div><div>                    </div><div>               <img src="7.5 非线性回归 logistic regression_files/001QAImHgy6I1otAWE890&690.jpg" type="image/jpeg" height="222" style="cursor: default;cursor: default;cursor: default;cursor: default;cursor: default;cursor: default;cursor: default;cursor: default;cursor: default;cursor: default;" width="690"/></div><div>     <img src="7.5 非线性回归 logistic regression_files/001QAImHgy6I1oudixl13&690.jpg" type="image/jpeg" style="cursor: default;cursor: default;cursor: default;cursor: default;cursor: default;cursor: default;cursor: default;cursor: default;cursor: default;"/></div><div>          </div><div>          </div><div>           <img src="7.5 非线性回归 logistic regression_files/001QAImHgy6I1owps7Ud2&690.jpg" type="image/jpeg" style="cursor: default;cursor: default;cursor: default;cursor: default;cursor: default;cursor: default;cursor: default;cursor: default;"/></div><div>            找到合适的 θ0，θ1使上式最小</div><div><br/></div><div>          Logistic regression:</div><div>               </div><div>           Cost函数：<img src="7.5 非线性回归 logistic regression_files/001QAImHgy6I1oEKVWg50&690.jpg" type="image/jpeg" height="138" style="cursor: default;cursor: default;cursor: default;cursor: default;cursor: default;cursor: default;cursor: default;" width="690"/></div><div><br/></div><div><br/></div><div>            目标：找到合适的 θ0，θ1使上式最小</div><div>             </div><div>          2.4 解法：梯度下降（gradient decent)</div><div><br/></div><div>               <img src="7.5 非线性回归 logistic regression_files/imgres.jpg" type="image/jpeg" style="cursor: default;cursor: default;cursor: default;cursor: default;"/><img src="7.5 非线性回归 logistic regression_files/imgres [1].jpg" type="image/jpeg" style="cursor: default;cursor: default;cursor: default;"/></div><div>                         </div><div><br/></div><div><br/></div><div>                         <img src="7.5 非线性回归 logistic regression_files/001QAImHgy6I1oGTmnA36&690.jpg" type="image/jpeg" style="cursor: default;cursor: default;"/></div><div><br/></div><div>          </div><div><br/></div><div><br/></div><div>              更新法则：</div><div>               <img src="7.5 非线性回归 logistic regression_files/001QAImHgy6I1oJm3Qz27&690.jpg" type="image/jpeg" style="cursor: default;cursor: default;cursor: default;cursor: default;cursor: default;cursor: default;"/></div><div><br/></div><div>                      学习率</div><div>                      同时对所有的θ进行更新</div><div>                      重复更新直到收敛   </div><div><br/></div></div>
</div></body></html> 